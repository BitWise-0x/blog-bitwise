---
title: 'Introducing HumeChat: Voice AI with Emotional Intelligence'
date: '2026-01-15'
lastmod: '2026-02-15'
tags: ['ai', 'projects', 'humechat', 'voice-ai', 'hume', 'emotion-detection', 'psychology']
draft: false
summary: 'How I built a voice AI platform with real-time emotion detection across 48 categories, custom personas, voice cloning, and a Jungian self-discovery experience.'
images: ['/static/images/blog/humechat/emotion-empathy-face.jpg']
authors: ['default']
---

Although voice-based AI interfaces have grown considerably in both capability and adoption, the predominant approach continues to treat speech as a transcription problem. The semantic content of what is said receives all the attention, while the rich emotional signals embedded in tone, rhythm, hesitation, and emphasis are largely discarded. This is a significant limitation: in human conversation, how something is said often carries as much meaning as the words themselves.

<Image
  src="/static/images/blog/humechat/emotion-empathy-face.jpg"
  alt="Face illuminated by multicolored light projections, symbolizing AI emotion detection"
  width={800}
  height={450}
/>

The question that motivated this project was straightforward: what becomes possible when an AI system can detect and respond to a speaker's emotional state in real time, rather than simply processing their words? This post introduces [HumeChat](https://humechat.com), a voice AI platform I built to explore that question. It encompasses three distinct products (Playground, Archetype, and Wooza), each applying emotionally-aware voice interaction to a different context. In the sections that follow, I walk through the foundational emotion detection capability and the design thinking behind each product.

## Why I Built HumeChat

The impetus for HumeChat came from a dissatisfaction with the state of voice AI conversations. Even the most capable voice assistants operate on a fundamentally incomplete picture of the interaction: they capture the transcript but lose the affect. The frustration in someone's voice, the excitement behind a question, the hesitation that signals uncertainty: none of this informs the AI's response. I wanted to build something where emotion functions as a first-class input, shaping the conversation in real time rather than being discarded at the point of transcription.

[Hume AI's](https://hume.ai) Enhanced Voice Interface (EVI) technology provided the right foundation for this. Their prosody analysis is capable of detecting 48 distinct emotions from voice alone, analyzing tone, pitch, rhythm, and pauses, and it runs continuously throughout a conversation rather than producing a single summary score after the fact. HumeChat is the platform I built on top of that capability, exploring three different applications of emotionally-aware voice interaction: Playground, which serves as an open-ended persona builder for voice AI companions; Archetype, which pairs Jungian depth psychology with real-time emotional awareness; and Wooza, a children's voice companion designed for educational contexts.

<ZoomableImage
  src="/static/images/blog/humechat/humechat-landing1.png"
  alt="HumeChat landing page showing Playground, Archetype, and Wooza products"
  width={800}
  height={450}
/>

<ZoomableImage
  src="/static/images/blog/humechat/about.png"
  alt="HumeChat About page, AI Voice Interface with Emotional Intelligence"
  width={800}
  height={450}
/>

Before examining each product in detail, it is worth understanding the foundational capability that underpins all three: real-time emotion detection.

## Real-Time Emotion Detection

The distinguishing characteristic of HumeChat's approach lies in treating emotion detection not as an afterthought or summary metric, but as a continuous process that operates throughout every voice session. As a user speaks, Hume's prosody analysis tracks emotional shifts as they happen, producing a granular breakdown across 48 categories. These categories span a wide range of human affect, from Calmness, Contemplation, and Determination to Realization, Empathic Pain, and Awkwardness, each assigned a precise percentage and organized into six broader groupings: Positive, Social, Cognitive, Calm, Negative, and Distress.

<ZoomableImage
  src="/static/images/blog/humechat/emotion-tracking2.png"
  alt="Playground dashboard showing conversation transcript with inline emotion detection"
  width={800}
  height={450}
/>

Every message in the conversation transcript receives its own emotion breakdown. The dashboard surfaces the top detected emotions inline alongside each message, with the option to expand and view all 48 categories in detail. This data is not merely informational. It feeds directly into session analysis, persona adaptation, and the clinical work within Archetype, making emotional awareness a persistent thread that runs through the entire platform.

<ZoomableImage
  src="/static/images/blog/humechat/emotion-tracking1.png"
  alt="All 48 detected emotions organized by category"
  width={800}
  height={450}
/>

With this emotional awareness operating as a shared foundation, let us examine how each of the three products employs it in practice, beginning with Playground.

## Playground

Playground represents the most open-ended of HumeChat's three products. Where the other two apply emotion detection within specific frameworks (depth psychology and children's education, respectively), Playground offers unconstrained creative freedom, allowing users to build any voice AI companion they can envision.

<ZoomableImage
  src="/static/images/blog/humechat/playground1.png"
  alt="Playground landing, AI Persona Builder with Custom Personas and Voice Cloning"
  width={800}
  height={450}
/>

Each persona encompasses a configurable voice, drawn from over 159 presets spanning multiple languages and accents, or alternatively cloned from user-uploaded audio samples. The underlying language model can be selected from more than 25 options, including Claude, GPT-4, Llama, Gemini, and Groq, allowing the persona to be optimized for its intended purpose. Personality and conversational style are defined through custom system prompts, while a persistent memory system retains context across sessions, enabling the persona to learn the user's communication style and preferences over time.

<ZoomableImage
  src="/static/images/blog/humechat/playground2.png"
  alt="Playground interface with persona selection, voice cloning, and Start Call"
  width={800}
  height={450}
/>

Conversations are conducted over WebSocket with sub-second latency, with reactive audio visualizations and a live transcript view accompanying each session.

While Playground offers this unconstrained creative freedom in persona design, the second product, Archetype, applies a far more structured framework to the conversation experience, one grounded in the analytical psychology of Carl Jung.

## Archetype

Archetype is the product I am most personally invested in. The premise that drew me to it was the convergence of two capabilities that had not been meaningfully combined before: depth psychology as a conversational framework, and real-time access to the speaker's emotional state. I wanted to explore what a Carl Jung persona could do when it can perceive not only what someone says but how they feel as they say it.

<ZoomableImage
  src="/static/images/blog/humechat/archetype1.png"
  alt="Archetype landing, Jungian Self-Discovery with Assessment and Talk to Carl Jung"
  width={800}
  height={450}
/>

For those less familiar with Jung's framework, a brief orientation may be useful. Archetypes, in the Jungian sense, are universal psychological patterns, recurring motifs of thought and behavior that shape how individuals engage with the world. The shadow refers to the repressed or unacknowledged aspects of one's personality, while the anima and animus represent the contrasexual inner figures that influence how we relate to others. Individuation is Jung's term for the lifelong process of integrating these elements into a more complete and self-aware whole. Archetype translates these concepts into a structured self-discovery experience: archetype profiling, shadow integration, anima and animus exploration, and a four-stage individuation journey, all conducted through emotionally-aware voice conversation.

<ZoomableImage
  src="/static/images/blog/humechat/archetype.png"
  alt="Archetype information page showing four-stage individuation journey and expectations"
  width={800}
  height={450}
/>

### How It Works

The experience begins with a 12-question assessment, which generates a personalized dashboard reflecting the user's archetypal profile. From there, users progress through a structured individuation journey, engaging in voice sessions with a Carl Jung persona that has access to their emotional state in real time. Following each session, an AI clinical analysis is performed, and progress is tracked over time to surface patterns of growth and areas requiring further exploration.

<ZoomableImage
  src="/static/images/blog/humechat/archetype-workflow.png"
  alt="Archetype workflow from Assessment through Clinical Analysis to Track Growth"
  width={800}
  height={450}
/>

### Your Archetype Profile

The entry point is a 12-question assessment based on Carol Pearson's Pearson-Marr Archetype Indicator (PMAI), a well-established framework for identifying dominant psychological patterns. The assessment identifies dominant, secondary, tertiary, and shadow archetypes from a taxonomy of twelve types. Pearson's framework organizes these archetypes into three groups, each corresponding to a different dimension of psychological development:

- **Ego archetypes:** Innocent, Orphan, Hero, Caregiver
- **Soul archetypes:** Explorer, Destroyer, Lover, Creator
- **Self archetypes:** Ruler, Magician, Sage, Jester

The result is a full archetypal blend with percentage weightings for each archetype, along with an identification of the shadow archetype, the pattern most actively repressed or avoided.

<ZoomableImage
  src="/static/images/blog/humechat/archetype-journey.png"
  alt="Archetype profile showing archetypal blend with Sage 30%, Lover 21%, Creator 19% and Shadow Archetype identification"
  width={800}
  height={450}
/>

### Voice Sessions & Clinical Analysis

Voice sessions with Carl Jung are personalized to the user's archetype profile and current individuation stage. Real-time emotion detection runs throughout, allowing Carl to perceive and adapt to the speaker's emotional state as the conversation unfolds, a dimension of awareness that traditional text-based interactions cannot provide.

After each session, Claude Opus 4 performs a clinical analysis grounded in Jungian methodology. Each assessment is tagged with therapeutic indicators (such as "Therapeutically Substantive," "Shadow Present," and "Integration Movement") and measures affective engagement on a spectrum from intellectual to deep. Sessions are classified as "Emerging" or "Defended" based on the depth and authenticity of engagement observed.

<ZoomableImage
  src="/static/images/blog/humechat/archetype-analysis.png"
  alt="Archetype clinical analysis dashboard showing session assessments with therapeutic tags"
  width={800}
  height={450}
/>

Progress through the four individuation stages (Persona, Shadow, Anima/Animus, and Self) is quantified through a stage readiness score calculated from the last five sessions. Advancing to the next stage requires reaching 80% readiness, a threshold based on genuine therapeutic work rather than mere participation. The platform operates on a full transparency model, exposing everything to the user: Carl's private clinical notes, affective engagement levels, resistance patterns, and session-by-session insights. The intent is that self-discovery should not be opaque; the process itself should be visible.

While Archetype represents perhaps the most ambitious application of emotionally-aware voice AI in the platform, HumeChat's third product explores a very different context: conversations designed for children.

## Wooza

Wooza is a children's voice companion, currently in development. The motivation behind it was a curiosity about whether emotionally-aware voice AI could serve younger users in an educational context, and whether the same prosody analysis that detects nuance in adult conversation could also sense when a child is confused, frustrated, or losing interest, and adjust accordingly.

<ZoomableImage
  src="/static/images/blog/humechat/wooza1.png"
  alt="Wooza, Meet Buster the friendly AI troll for kids with homework help, storytelling, and reading practice"
  width={800}
  height={450}
/>

At its center is Buster, a friendly AI character designed specifically for younger users. Buster can assist with homework across subjects such as mathematics and science, guide children through interactive storytelling adventures, provide feedback during reading practice, and serve as a patient listener for any question a child might have.

The design philosophy for Wooza prioritizes safety above all else. Unlike Playground, there is no persona customization. The experience is entirely controlled, with responses constrained to child-friendly content and the interface designed to maintain focus on learning and enjoyment. This deliberate limitation reflects a recognition that the flexibility appropriate for adult users requires a fundamentally different set of guardrails when the audience is children.

## Platform Overview

<ZoomableImage
  src="/static/images/blog/humechat/features.png"
  alt="HumeChat feature overview"
  width={800}
  height={450}
/>

At the infrastructure level, HumeChat is built around WebSocket-powered real-time voice chat with sub-second latency and continuous 48-emotion prosody analysis during every session. The persona system supports unlimited custom AI companions, each with a selectable language model from over 25 options (including Claude, GPT-4, Llama, Gemini, and Groq), voice selection from 159+ presets or cloned from uploaded samples, and persistent memory that retains context across sessions and learns user preferences over time.

On the analytics and self-discovery side, the platform provides a personal dashboard encompassing conversation history, full transcripts, emotion tracking, and audio downloads. For users engaged with Archetype, this extends to Jungian archetype profiling with structured AI clinical analysis, a capability that ties the platform's emotional awareness to a deeper framework for self-understanding.

## Conclusion

Building HumeChat has been an exercise in exploring what becomes possible when emotional awareness is treated not as a novelty feature but as a foundational input to voice AI interaction. The platform is, in many respects, still early in its development. Wooza remains a work in progress, and the clinical analysis capabilities within Archetype continue to be refined. But the core premise has proven compelling: that voice AI which can perceive how someone feels, not merely what they say, opens a meaningfully different design space.

To what extent can prosody analysis deepen the therapeutic potential of AI-guided self-discovery? Can emotionally-aware voice interfaces genuinely support psychological work, or will they remain constrained to surface-level adaptation? What does it mean for a children's educational companion to sense frustration or disengagement in real time? These are questions I find worth pursuing, and HumeChat is the vehicle through which I am exploring them.

For those interested in trying the platform, HumeChat offers a free demo requiring no account, with ten minutes of daily voice AI conversation that includes access to public personas and emotion detection. Full access, encompassing custom persona creation, voice cloning, persistent memory, and the personal dashboard, is currently available on an invite basis and can be requested through the [sign-in page](https://humechat.com/auth/signin).
